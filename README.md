# Quality and Safety for LLM Applications

![](https://encrypted-tbn0.gstatic.com/images?q=tbn:ANd9GcT5ALdS7LaJcqeycTkyQPAauIIwAHB_D6gNWQ&usqp=CAU)

Data privacy in LLMs pertains to protecting the personal information that may be included in the training datasets or generated in the model's outputs. It involves ensuring that data is anonymized, consent is obtained where necessary, and that the model does not inadvertently reveal sensitive information.

WhyLabs is the essential AI Observability Platform for model and data health. It is the only machine learning monitoring and observability platform that doesn't operate on raw data, which enables a no-configuration solution, privacy preservation, and massive scale.

The WhyLabs Platform is custom built to ingest and monitor statistical summaries generated by the whylogs and LangKit open source libraries. These summaries are commonly referred to "whylogs profiles", and enable privacy-preserving observability and monitoring at scale.

Machine learning engineers and data scientists rely on the platform to monitor ML applications and data pipelines by surfacing and resolving data quality issues, data bias, and concept drift. These capabilities help AI builders reduce model failures, avoid downtime, and ensure customers are getting the best user experience. With out-of-the-box anomaly detection and purpose-built visualizations, WhyLabs eliminates the need for manual troubleshooting and reduces operational costs.

The platform can monitor tabular, image, and text data. It integrates with many popular ML and data tools including Pandas, Apache Spark, AWS Sagemaker, MLflow, Flask, Ray, RAPIDS, Apache Kafka, and more. To learn more about what data types WhyLabs can work with and which tools we integrate with, check out the whylogs [GitHub page](https://github.com/whylabs/whylogs)
